{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-05T11:20:20.189313Z",
     "start_time": "2025-05-05T11:20:20.136435Z"
    }
   },
   "source": [
    "from sqlalchemy.dialects.oracle.dictionary import all_objects\n",
    "\n",
    "from models.TrackedObject import TrackedObject\n",
    "from models.VideoAnalysis import VideoAnalysis\n",
    "from utils.dynamics import EuclideanDistTracker, get_overlap_info\n",
    "import utils.files as fil\n",
    "import cv2\n",
    "import os\n",
    "import analysis.mask_rcnn as mask_rcnn\n",
    "from analysis import yolo\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 225
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "isColab=False\n",
    "if isColab:\n",
    "    from google.colab.patches import cv2_imshow\n",
    "    from google.colab import drive\n",
    "from IPython.display import display, clear_output\n",
    "import PIL.Image\n",
    "\n",
    "tracker = EuclideanDistTracker()\n",
    "transform, COCO_INSTANCE_CATEGORY_NAMES, model, device= mask_rcnn.config()\n",
    "model= yolo.config()\n",
    "\n",
    "\n",
    "\n",
    "def process_clip(frame_filenames):\n",
    "    frame_filenames = [os.path.join(frames_folder, f) for f in frame_filenames]\n",
    "    va=VideoAnalysis()\n",
    "    # Get frame size dynamically from the first frame\n",
    "    sample_frame = cv2.imread(frame_filenames[0])\n",
    "    height, width = sample_frame.shape[:2]\n",
    "    frame_size = (width, height)\n",
    "    fps = 18\n",
    "\n",
    "    # Save output to MP4 instead of AVI\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or use 'avc1' for better compatibility\n",
    "    out = cv2.VideoWriter(\"output_file.mp4\", fourcc, fps, frame_size)\n",
    "\n",
    "    for frame_filename in frame_filenames:\n",
    "        frame = cv2.imread(frame_filename)\n",
    "        if frame is None:\n",
    "            continue\n",
    "        #result_frame,_,_objects = mask_rcnn.process_frame(model, frame, device, transform, COCO_INSTANCE_CATEGORY_NAMES, tracker, conf=0.5)\n",
    "        result_frame, _objects = yolo.process_frame(model, frame, device, transform, COCO_INSTANCE_CATEGORY_NAMES, tracker, conf=0.5)\n",
    "        for o in va.allObjects:\n",
    "          o.is_present=False\n",
    "          o.is_accident=False\n",
    "        for obj in _objects:\n",
    "          if obj.id>(len(va.allObjects)-1):\n",
    "            va.allObjects.append(obj)\n",
    "          else:\n",
    "            o=va.allObjects[obj.id]\n",
    "            o.id=obj.id\n",
    "            o.is_present=obj.is_present\n",
    "            o.x1=obj.x1\n",
    "            o.x2=obj.x2\n",
    "            o.y1=obj.y1\n",
    "            o.y2=obj.y2\n",
    "            o.centroid=obj.centroid\n",
    "            o.overlaps=obj.overlaps\n",
    "            o.past_centroids.append(obj.centroid)\n",
    "            o.compute_speed()\n",
    "            o.compute_acceleration()\n",
    "            o.compute_vector()\n",
    "            #print(str(o.id)+str(o.is_accident)+str(o.centroid))\n",
    "        get_overlap_info(va.allObjects)\n",
    "        for box in va.allObjects:\n",
    "            box.check_accident()\n",
    "            #cv2.putText(result_frame, str(box.acceleration),(box.x1, box.y1 - 10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 2)\n",
    "            if box.is_accident:\n",
    "              cv2.rectangle(result_frame, (box.x1, box.y1), (box.x2, box.y2), (0, 255, 255), 3)\n",
    "        #print(frame_filename)\n",
    "        out.write(result_frame)\n",
    "        if isColab:\n",
    "            #Convert to PIL format for proper display in Jupyter/Colab\n",
    "            #Display only the current frame\n",
    "            #clear_output(wait=True)\n",
    "            result_frame_rgb = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            result_pil = PIL.Image.fromarray(result_frame_rgb)\n",
    "            display(result_pil)\n",
    "        else:\n",
    "            cv2.imshow('res',result_frame)\n",
    "            if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "                  break\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "62e76456fc0e4c32",
   "execution_count": 228,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40  Python-3.12.7 torch-2.5.1+cpu CPU (12th Gen Intel Core(TM) i5-1235U)\n",
      "Setup complete  (12 CPUs, 15.7 GB RAM, 399.1/454.3 GB disk)\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-05T11:31:57.343754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if isColab:\n",
    "    # Process video frames\n",
    "    drive.mount('/content/drive/',force_remount=True)\n",
    "    frames_folder = '/content/drive/MyDrive/Yolo/001102'\n",
    "else:\n",
    "    frames_folder = './data/accident/cadp_001102'\n",
    "\n",
    "\n",
    "\n",
    "frame_filenames= sorted(\n",
    "    [f for f in os.listdir(frames_folder) if f.endswith('.jpg')],\n",
    "    key=fil.extract_number\n",
    ")\n",
    "process_clip(frame_filenames)"
   ],
   "id": "647e5a863a177cf9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 325.0ms\n",
      "Speed: 0.0ms preprocess, 325.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 351.2ms\n",
      "Speed: 0.0ms preprocess, 351.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 326.4ms\n",
      "Speed: 0.0ms preprocess, 326.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 327.4ms\n",
      "Speed: 0.0ms preprocess, 327.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 320.3ms\n",
      "Speed: 0.0ms preprocess, 320.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 297.8ms\n",
      "Speed: 0.0ms preprocess, 297.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 341.7ms\n",
      "Speed: 0.0ms preprocess, 341.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 321.7ms\n",
      "Speed: 0.0ms preprocess, 321.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 300.9ms\n",
      "Speed: 0.0ms preprocess, 300.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 302.5ms\n",
      "Speed: 0.0ms preprocess, 302.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 304.7ms\n",
      "Speed: 0.0ms preprocess, 304.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 306.4ms\n",
      "Speed: 0.0ms preprocess, 306.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 301.0ms\n",
      "Speed: 0.0ms preprocess, 301.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 311.2ms\n",
      "Speed: 0.0ms preprocess, 311.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 304.6ms\n",
      "Speed: 0.0ms preprocess, 304.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 300.4ms\n",
      "Speed: 0.0ms preprocess, 300.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 308.2ms\n",
      "Speed: 0.0ms preprocess, 308.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 309.1ms\n",
      "Speed: 0.0ms preprocess, 309.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 302.1ms\n",
      "Speed: 0.0ms preprocess, 302.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 300.9ms\n",
      "Speed: 0.0ms preprocess, 300.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 300.6ms\n",
      "Speed: 8.2ms preprocess, 300.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 308.8ms\n",
      "Speed: 0.0ms preprocess, 308.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 331.4ms\n",
      "Speed: 0.0ms preprocess, 331.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 309.1ms\n",
      "Speed: 0.0ms preprocess, 309.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 316.0ms\n",
      "Speed: 0.0ms preprocess, 316.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 298.9ms\n",
      "Speed: 0.0ms preprocess, 298.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T11:15:52.675721Z",
     "start_time": "2025-05-05T11:15:52.667019Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "42088fe9782cc683",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T17:10:12.022863Z",
     "start_time": "2025-04-27T17:10:12.017957Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "58e0e06a26648a18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9cedeb4744f73180"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
