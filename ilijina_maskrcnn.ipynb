{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-04T15:03:14.361075Z",
     "start_time": "2025-05-04T15:03:14.308796Z"
    }
   },
   "source": [
    "from models.TrackedObject import TrackedObject\n",
    "from models.VideoAnalysis import VideoAnalysis\n",
    "from utils.dynamics import EuclideanDistTracker, get_overlap_info\n",
    "import utils.files as fil\n",
    "import cv2\n",
    "import os\n",
    "import analysis.mask_rcnn as mask_rcnn\n",
    "from analysis import yolo\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "isColab=False\n",
    "if isColab:\n",
    "    from google.colab.patches import cv2_imshow\n",
    "    from google.colab import drive\n",
    "from IPython.display import display, clear_output\n",
    "import PIL.Image\n",
    "\n",
    "tracker = EuclideanDistTracker()\n",
    "transform, COCO_INSTANCE_CATEGORY_NAMES, model, device= mask_rcnn.config()\n",
    "model= yolo.config()\n",
    "\n",
    "\n",
    "if isColab:\n",
    "    # Process video frames\n",
    "    drive.mount('/content/drive/',force_remount=True)\n",
    "    frames_folder = '/content/drive/MyDrive/Yolo/001102'\n",
    "else:\n",
    "    frames_folder = './data/accident/cadp_001102'\n",
    "\n",
    "\n",
    "\n",
    "frame_filenames= sorted(\n",
    "    [f for f in os.listdir(frames_folder) if f.endswith('.jpg')],\n",
    "    key=fil.extract_number\n",
    ")\n",
    "def process_clip(frame_filenames):\n",
    "    frame_filenames = [os.path.join(frames_folder, f) for f in frame_filenames]\n",
    "    va=VideoAnalysis()\n",
    "    # Get frame size dynamically from the first frame\n",
    "    sample_frame = cv2.imread(frame_filenames[0])\n",
    "    height, width = sample_frame.shape[:2]\n",
    "    frame_size = (width, height)\n",
    "    fps = 18\n",
    "\n",
    "    # Save output to MP4 instead of AVI\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or use 'avc1' for better compatibility\n",
    "    out = cv2.VideoWriter(\"output_file.mp4\", fourcc, fps, frame_size)\n",
    "\n",
    "    for frame_filename in frame_filenames:\n",
    "        frame = cv2.imread(frame_filename)\n",
    "        if frame is None:\n",
    "            continue\n",
    "        #result_frame,_,_objects = mask_rcnn.process_frame(model, frame, device, transform, COCO_INSTANCE_CATEGORY_NAMES, tracker, conf=0.5)\n",
    "        result_frame, _objects = yolo.process_frame(model, frame, device, transform, COCO_INSTANCE_CATEGORY_NAMES, tracker, conf=0.5)\n",
    "        prev_objects=_objects\n",
    "        for o in va.allObjects:\n",
    "          o.is_present=False\n",
    "          o.is_accident=False\n",
    "        for obj in _objects:\n",
    "          if obj.id>(len(va.allObjects)-1):\n",
    "            va.allObjects.append(obj)\n",
    "          else:\n",
    "            o=va.allObjects[obj.id]\n",
    "            o.id=obj.id\n",
    "            o.is_present=obj.is_present\n",
    "            o.x1=obj.x1\n",
    "            o.x2=obj.x2\n",
    "            o.y1=obj.y1\n",
    "            o.y2=obj.y2\n",
    "            o.centroid=obj.centroid\n",
    "            o.overlaps=obj.overlaps\n",
    "            o.past_centroids.append(obj.centroid)\n",
    "            o.compute_speed()\n",
    "            o.compute_acceleration()\n",
    "            o.check_accident()\n",
    "            #print(str(o.id)+str(o.is_accident)+str(o.centroid))\n",
    "        for box in va.allObjects:\n",
    "            #cv2.putText(result_frame, str(box.acceleration),(box.x1, box.y1 - 10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 2)\n",
    "            if box.is_accident:\n",
    "              cv2.rectangle(result_frame, (box.x1, box.y1), (box.x2, box.y2), (0, 255, 255), 3)\n",
    "        #print(frame_filename)\n",
    "        out.write(result_frame)\n",
    "        if isColab:\n",
    "            #Convert to PIL format for proper display in Jupyter/Colab\n",
    "            #Display only the current frame\n",
    "            #clear_output(wait=True)\n",
    "            result_frame_rgb = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            result_pil = PIL.Image.fromarray(result_frame_rgb)\n",
    "            display(result_pil)\n",
    "        else:\n",
    "            cv2.imshow('res',result_frame)\n",
    "            if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "                  break\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "62e76456fc0e4c32",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40  Python-3.12.7 torch-2.5.1+cpu CPU (12th Gen Intel Core(TM) i5-1235U)\n",
      "Setup complete  (12 CPUs, 15.7 GB RAM, 393.0/454.3 GB disk)\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T15:03:14.031212Z",
     "start_time": "2025-05-04T15:02:43.508541Z"
    }
   },
   "cell_type": "code",
   "source": "process_clip(frame_filenames)",
   "id": "647e5a863a177cf9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 509.7ms\n",
      "Speed: 13.0ms preprocess, 509.7ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 353.8ms\n",
      "Speed: 1.5ms preprocess, 353.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 334.3ms\n",
      "Speed: 1.9ms preprocess, 334.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 368.6ms\n",
      "Speed: 0.0ms preprocess, 368.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 345.9ms\n",
      "Speed: 4.5ms preprocess, 345.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 333.8ms\n",
      "Speed: 0.0ms preprocess, 333.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 369.1ms\n",
      "Speed: 0.0ms preprocess, 369.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 345.0ms\n",
      "Speed: 0.0ms preprocess, 345.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 345.5ms\n",
      "Speed: 0.0ms preprocess, 345.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 368.5ms\n",
      "Speed: 0.4ms preprocess, 368.5ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 357.9ms\n",
      "Speed: 1.1ms preprocess, 357.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 321.4ms\n",
      "Speed: 17.0ms preprocess, 321.4ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 298.4ms\n",
      "Speed: 0.0ms preprocess, 298.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 296.1ms\n",
      "Speed: 0.0ms preprocess, 296.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 296.1ms\n",
      "Speed: 0.0ms preprocess, 296.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 288.4ms\n",
      "Speed: 0.0ms preprocess, 288.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 299.5ms\n",
      "Speed: 0.0ms preprocess, 299.5ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 294.7ms\n",
      "Speed: 8.8ms preprocess, 294.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 302.3ms\n",
      "Speed: 0.0ms preprocess, 302.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 279.7ms\n",
      "Speed: 8.0ms preprocess, 279.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 302.9ms\n",
      "Speed: 0.0ms preprocess, 302.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 298.2ms\n",
      "Speed: 0.0ms preprocess, 298.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 297.5ms\n",
      "Speed: 0.0ms preprocess, 297.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 309.5ms\n",
      "Speed: 0.0ms preprocess, 309.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 311.0ms\n",
      "Speed: 0.0ms preprocess, 311.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 294.3ms\n",
      "Speed: 0.0ms preprocess, 294.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 316.3ms\n",
      "Speed: 0.0ms preprocess, 316.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 304.0ms\n",
      "Speed: 13.5ms preprocess, 304.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 307.5ms\n",
      "Speed: 0.0ms preprocess, 307.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 304.9ms\n",
      "Speed: 0.0ms preprocess, 304.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 308.0ms\n",
      "Speed: 0.0ms preprocess, 308.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 295.4ms\n",
      "Speed: 0.0ms preprocess, 295.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 290.0ms\n",
      "Speed: 0.0ms preprocess, 290.0ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 316.7ms\n",
      "Speed: 0.0ms preprocess, 316.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 305.3ms\n",
      "Speed: 0.0ms preprocess, 305.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 302.4ms\n",
      "Speed: 0.0ms preprocess, 302.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 279.6ms\n",
      "Speed: 0.0ms preprocess, 279.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 283.1ms\n",
      "Speed: 0.0ms preprocess, 283.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 315.6ms\n",
      "Speed: 0.0ms preprocess, 315.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 309.1ms\n",
      "Speed: 0.0ms preprocess, 309.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 307.3ms\n",
      "Speed: 10.6ms preprocess, 307.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 287.9ms\n",
      "Speed: 8.0ms preprocess, 287.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 295.8ms\n",
      "Speed: 0.0ms preprocess, 295.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 305.0ms\n",
      "Speed: 0.0ms preprocess, 305.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 310.6ms\n",
      "Speed: 0.0ms preprocess, 310.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 310.2ms\n",
      "Speed: 0.0ms preprocess, 310.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 327.8ms\n",
      "Speed: 0.0ms preprocess, 327.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 355.4ms\n",
      "Speed: 0.0ms preprocess, 355.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 314.2ms\n",
      "Speed: 0.0ms preprocess, 314.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 309.2ms\n",
      "Speed: 0.0ms preprocess, 309.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 298.2ms\n",
      "Speed: 9.7ms preprocess, 298.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 309.9ms\n",
      "Speed: 0.0ms preprocess, 309.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 311.3ms\n",
      "Speed: 0.0ms preprocess, 311.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 293.3ms\n",
      "Speed: 0.0ms preprocess, 293.3ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 304.8ms\n",
      "Speed: 0.0ms preprocess, 304.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 320.2ms\n",
      "Speed: 0.0ms preprocess, 320.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 296.7ms\n",
      "Speed: 0.0ms preprocess, 296.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-12.535884028138744\n",
      "-12.535884028138744\n",
      "ACCIDENT!!!\n",
      "\n",
      "0: 384x640 2 cars, 296.0ms\n",
      "Speed: 0.0ms preprocess, 296.0ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 296.0ms\n",
      "Speed: 0.0ms preprocess, 296.0ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 293.2ms\n",
      "Speed: 0.0ms preprocess, 293.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 310.4ms\n",
      "Speed: 0.0ms preprocess, 310.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 311.6ms\n",
      "Speed: 0.0ms preprocess, 311.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 307.8ms\n",
      "Speed: 4.5ms preprocess, 307.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 350.9ms\n",
      "Speed: 0.0ms preprocess, 350.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 322.4ms\n",
      "Speed: 0.0ms preprocess, 322.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 295.8ms\n",
      "Speed: 0.0ms preprocess, 295.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 303.9ms\n",
      "Speed: 0.0ms preprocess, 303.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 304.4ms\n",
      "Speed: 0.0ms preprocess, 304.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 305.3ms\n",
      "Speed: 0.0ms preprocess, 305.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 294.5ms\n",
      "Speed: 0.0ms preprocess, 294.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 305.4ms\n",
      "Speed: 0.0ms preprocess, 305.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 295.8ms\n",
      "Speed: 0.0ms preprocess, 295.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 294.3ms\n",
      "Speed: 0.0ms preprocess, 294.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 312.6ms\n",
      "Speed: 0.0ms preprocess, 312.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 320.7ms\n",
      "Speed: 0.0ms preprocess, 320.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:56:02.626335Z",
     "start_time": "2025-04-27T23:38:12.694895Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "42088fe9782cc683",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T17:10:12.022863Z",
     "start_time": "2025-04-27T17:10:12.017957Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "58e0e06a26648a18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9cedeb4744f73180"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
