{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-11T21:56:02.815982Z",
     "start_time": "2025-06-11T21:55:56.643899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A,B,G=0,0,0\n",
    "isColab=False\n",
    "if isColab:\n",
    "    %pip install ultralytics\n",
    "    import ultralytics\n",
    "    ultralytics.checks()\n",
    "    from google.colab.patches import cv2_imshow\n",
    "    from google.colab import drive\n",
    "from sqlalchemy.dialects.oracle.dictionary import all_objects\n",
    "import csv\n",
    "import pickle\n",
    "from models.TrackedObject import TrackedObject\n",
    "from models.VideoAnalysis import VideoAnalysis\n",
    "from utils.dynamics import EuclideanDistTracker, get_overlap_info\n",
    "import utils.files as fil\n",
    "import cv2\n",
    "import os\n",
    "import analysis.mask_rcnn as mask_rcnn\n",
    "from analysis import yolo\n",
    "from utils.visualise import visualize\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import PIL.Image"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomfi\\master_thesis\\models\\TrackedObject.py:143: SyntaxWarning: invalid decimal literal\n",
      "  if beta>=(3/4)*3.15and beta<(4/4)*3.15:\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "transform, COCO_INSTANCE_CATEGORY_NAMES, model, device= mask_rcnn.config()\n",
    "model= yolo.config()\n",
    "\n",
    "def run_detection(frame_filenames, detection_file_path):\n",
    "    if os.path.exists(detection_file_path):\n",
    "        print(\"Detection file already exists. Skipping YOLO detection.\")\n",
    "        return\n",
    "\n",
    "    print(\"Running YOLO detection and saving results...\")\n",
    "    all_detections = []\n",
    "    i=0\n",
    "    for frame_filename in frame_filenames:\n",
    "        i+=1\n",
    "        if i > 14000:\n",
    "            print(i)\n",
    "            frame = cv2.imread(frame_filename)\n",
    "            if frame is None:\n",
    "                all_detections.append([])  # Append empty detection for consistency\n",
    "                continue\n",
    "\n",
    "            detections = yolo.process_frame(model, frame, device, transform,\n",
    "                                            COCO_INSTANCE_CATEGORY_NAMES,\n",
    "                                            tracker=None,\n",
    "                                            conf=0.5)\n",
    "            all_detections.append(detections)\n",
    "            if i % 1000 == 0:\n",
    "\n",
    "                with open(detection_file_path+str(i), 'wb') as f:\n",
    "                    pickle.dump(all_detections, f)\n",
    "                    print(f\"Saved detections to {detection_file_path+str(i)}\")\n",
    "                    all_detections = []\n",
    "    with open(detection_file_path+str(i), 'wb') as f:\n",
    "        pickle.dump(all_detections, f)\n",
    "        print(f\"Saved detections to {detection_file_path+str(i)}\")\n",
    "        all_detections = []\n",
    "\n",
    "\n",
    "\n",
    "def process_clip(frame_filenames, case_folder, detection_file_path):\n",
    "    accident_cnt=0\n",
    "    detected_accidents = set()\n",
    "    acc_detected=False\n",
    "    tracker = EuclideanDistTracker()\n",
    "    va=VideoAnalysis()\n",
    "\n",
    "    # Load YOLO detections\n",
    "    if not os.path.exists(detection_file_path):\n",
    "        raise FileNotFoundError(f\"No detection file found at {detection_file_path}\")\n",
    "    with open(detection_file_path, 'rb') as f:\n",
    "        all_detections = pickle.load(f)\n",
    "\n",
    "\n",
    "    # Get frame size dynamically from the first frame\n",
    "    sample_frame = cv2.imread(frame_filenames[0])\n",
    "    height, width = sample_frame.shape[:2]\n",
    "    frame_size = (width, height)\n",
    "    fps = 18\n",
    "\n",
    "    # Save output to MP4 instead of AVI\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or use 'avc1' for better compatibility\n",
    "    out = cv2.VideoWriter(case_folder+\"_output_maskrcnn.mp4\", fourcc, fps, frame_size)\n",
    "\n",
    "    for idx, frame_filename in enumerate(frame_filenames):\n",
    "        frame = cv2.imread(frame_filename)\n",
    "        if frame is None:\n",
    "            continue\n",
    "        #result_frame,_,_objects = mask_rcnn.process_frame(model, frame, device, transform, COCO_INSTANCE_CATEGORY_NAMES, tracker, conf=0.5)\n",
    "        _objects = all_detections[idx]\n",
    "        boxes = tracker.update(_objects)\n",
    "        get_overlap_info(boxes)\n",
    "\n",
    "        for o in va.allObjects:\n",
    "          o.is_present=False\n",
    "          o.is_accident=False\n",
    "        for obj in boxes:\n",
    "          if obj.id>(len(va.allObjects)-1):\n",
    "            obj.H=height\n",
    "            va.allObjects.append(obj)\n",
    "          else:\n",
    "            o=va.allObjects[obj.id]\n",
    "            o.id=obj.id\n",
    "            o.is_present=obj.is_present\n",
    "            o.x1=obj.x1\n",
    "            o.x2=obj.x2\n",
    "            o.y1=obj.y1\n",
    "            o.y2=obj.y2\n",
    "            o.centroid=obj.centroid\n",
    "            o.overlaps=obj.overlaps\n",
    "            o.past_centroids.append(obj.centroid)\n",
    "            o.compute_speed()\n",
    "            o.compute_acceleration()\n",
    "            o.compute_vector()\n",
    "            #print(str(o.id)+str(o.is_accident)+str(o.centroid))\n",
    "        #va.allObjects=get_overlap_info(va.allObjects)\n",
    "        for box in va.allObjects:\n",
    "            box.check_accident(A, B, G)\n",
    "            if box.is_accident and box.id not in detected_accidents:\n",
    "                accident_cnt += 1\n",
    "                detected_accidents.add(box.id)\n",
    "        result_frame=visualize(frame, va.allObjects)\n",
    "        #print(frame_filename)\n",
    "        out.write(result_frame)\n",
    "        if isColab:\n",
    "            #Convert to PIL format for proper display in Jupyter/Colab\n",
    "            #Display only the current frame\n",
    "            #clear_output(wait=True)\n",
    "            result_frame_rgb = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            result_pil = PIL.Image.fromarray(result_frame_rgb)\n",
    "            display(result_pil)\n",
    "        else:\n",
    "            cv2.imshow('res',result_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                  break\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return acc_detected, accident_cnt\n"
   ],
   "id": "62e76456fc0e4c32",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40  Python-3.12.7 torch-2.5.1+cpu CPU (12th Gen Intel Core(TM) i5-1235U)\n",
      "Setup complete  (12 CPUs, 15.7 GB RAM, 440.7/454.3 GB disk)\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T22:27:27.593769Z",
     "start_time": "2025-06-06T22:27:08.288219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if isColab:\n",
    "    drive.mount('/content/drive/',force_remount=True)\n",
    "    frames = '/content/drive/MyDrive/data/normal/'\n",
    "else:\n",
    "    frames = './data/test/'\n",
    "\n",
    "results=[]\n",
    "A,B,G,T=-7,0,4,0\n",
    "for T in [25]:\n",
    "    folders = os.listdir(frames)\n",
    "    accident_count, total_count=0,0\n",
    "    for case_folder in folders:\n",
    "        frame_filenames= sorted(\n",
    "            [f for f in os.listdir(frames+case_folder) if f.endswith('.jpg')],\n",
    "            key=fil.extract_number\n",
    "        )\n",
    "\n",
    "        frame_filenames = [os.path.join(frames+case_folder, f) for f in frame_filenames]\n",
    "        detection_file_path = case_folder + \"_detections.pkl\"\n",
    "        if not os.path.exists(detection_file_path):\n",
    "            run_detection(frame_filenames, detection_file_path)\n",
    "        else:\n",
    "            print(f\"Detections already exist at {detection_file_path}. Skipping detection.\")\n",
    "        acc_detected, cnt = process_clip(frame_filenames, case_folder, detection_file_path)\n",
    "        if acc_detected == True:\n",
    "            accident_count+=1\n",
    "        total_count+=1\n",
    "    print (\"Total count: \",total_count)\n",
    "    print (\"Accident count: \",accident_count)\n",
    "    print (\"A\",A,\"B\",B,\"G\",G)\n",
    "\n",
    "    results.append({\n",
    "        \"A\": A,\n",
    "        \"total_count\": cnt,\n",
    "        \"accident_count\": accident_count,\n",
    "        \"B\": B,\n",
    "        \"G\": G\n",
    "    })\n",
    "csv_output_file = \"test_combined30.csv\"\n",
    "with open(csv_output_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = [\"A\", \"total_count\", \"accident_count\", \"B\", \"G\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)"
   ],
   "id": "8cca68b8194587e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detections already exist at combined_detections.pkl. Skipping detection.\n",
      "Loading detections from combined_detections.pkl1000\n",
      "Loading detections from combined_detections.pkl2000\n",
      "Loading detections from combined_detections.pkl3000\n",
      "Loading detections from combined_detections.pkl4000\n",
      "Loading detections from combined_detections.pkl5000\n",
      "Loading detections from combined_detections.pkl6000\n",
      "Loading detections from combined_detections.pkl7000\n",
      "Loading detections from combined_detections.pkl8000\n",
      "Loading detections from combined_detections.pkl9000\n",
      "Loading detections from combined_detections.pkl10000\n",
      "Loading detections from combined_detections.pkl11000\n",
      "Loading detections from combined_detections.pkl12000\n",
      "Loading detections from combined_detections.pkl13000\n",
      "Loading detections from combined_detections.pkl14000\n",
      "Loading detections from combined_detections.pkl15000\n",
      "Loading detections from combined_detections.pkl16000\n",
      "Loading detections from combined_detections.pkl17000\n",
      "Loading detections from combined_detections.pkl18000\n",
      "Loading detections from combined_detections.pkl19000\n",
      "Loading detections from combined_detections.pkl20000\n",
      "Loading detections from combined_detections.pkl21000\n",
      "Loading detections from combined_detections.pkl22000\n",
      "Loading detections from combined_detections.pkl23000\n",
      "Loading detections from combined_detections.pkl24000\n",
      "Loading detections from combined_detections.pkl25000\n",
      "Loading detections from combined_detections.pkl26000\n",
      "Loading detections from combined_detections.pkl27000\n",
      "Loading detections from combined_detections.pkl28000\n",
      "Loading detections from combined_detections.pkl29000\n",
      "Loading detections from combined_detections.pkl30000\n",
      "Loading detections from combined_detections.pkl31000\n",
      "Loading detections from combined_detections.pkl32000\n",
      "Loading detections from combined_detections.pkl33000\n",
      "Loading detections from combined_detections.pkl34000\n",
      "Loading detections from combined_detections.pkl35000\n",
      "Loading detections from combined_detections.pkl36000\n",
      "Loading detections from combined_detections.pkl37000\n",
      "Loading detections from combined_detections.pkl38000\n",
      "Loading detections from combined_detections.pkl39000\n",
      "Loading detections from combined_detections.pkl40000\n",
      "Loading detections from combined_detections.pkl41000\n",
      "Loading detections from combined_detections.pkl42000\n",
      "Loading detections from combined_detections.pkl43000\n",
      "Loading detections from combined_detections.pkl44000\n",
      "Loading detections from combined_detections.pkl45000\n",
      "Loading detections from combined_detections.pkl46000\n",
      "Loading detections from combined_detections.pkl47000\n",
      "Loading detections from combined_detections.pkl48000\n",
      "Loading detections from combined_detections.pkl49000\n",
      "Loading detections from combined_detections.pkl50000\n",
      "Loading detections from combined_detections.pkl51000\n",
      "Loading detections from combined_detections.pkl52000\n",
      "Loading detections from combined_detections.pkl53000\n",
      "Loading detections from combined_detections.pkl54000\n",
      "Loading detections from combined_detections.pkl55000\n",
      "Loading detections from combined_detections.pkl56000\n",
      "Loading detections from combined_detections.pkl57000\n",
      "Loading detections from combined_detections.pkl58000\n",
      "Loading detections from combined_detections.pkl58682\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[32]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     23\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mDetections already exist at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdetection_file_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m. Skipping detection.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m acc_detected, cnt = \u001B[43mprocess_clip\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe_filenames\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcase_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdetection_file_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m acc_detected == \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m     26\u001B[39m     accident_count+=\u001B[32m1\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[28]\u001B[39m\u001B[32m, line 113\u001B[39m, in \u001B[36mprocess_clip\u001B[39m\u001B[34m(frame_filenames, case_folder, detection_file_path)\u001B[39m\n\u001B[32m    111\u001B[39m result_frame=visualize(frame, va.allObjects)\n\u001B[32m    112\u001B[39m \u001B[38;5;66;03m#print(frame_filename)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m113\u001B[39m \u001B[43mout\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult_frame\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    114\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m isColab:\n\u001B[32m    115\u001B[39m     \u001B[38;5;66;03m#Convert to PIL format for proper display in Jupyter/Colab\u001B[39;00m\n\u001B[32m    116\u001B[39m     \u001B[38;5;66;03m#Display only the current frame\u001B[39;00m\n\u001B[32m    117\u001B[39m     \u001B[38;5;66;03m#clear_output(wait=True)\u001B[39;00m\n\u001B[32m    118\u001B[39m     result_frame_rgb = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)  \u001B[38;5;66;03m# Convert BGR to RGB\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T22:25:45.474349400Z",
     "start_time": "2025-06-02T18:01:46.232313Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e0b63d0354b93cb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6596fbf7e2e7413b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
